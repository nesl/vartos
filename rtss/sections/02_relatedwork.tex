\section{Related Work}

Power management and longevity in wireless sensor networks and low power embedded systems in general has long been an active area of research.  Traditional power management techniques have assumed that, while idle and active powers vary as a function of temperature, they remain uniform across instances.  Of these variability-agnostic techniques, many have focused on the tradeoff between energy and utility or performance.  For example, \cite{green2010, ghasemzadeh2012} represent attempts at making quality energy-proportional and tunable.  Specifically, \cite{green2010} introduces an architecture that allows developers to specify multiple versions of functions whereby the operating system can sacrifice quality when possible to reduce computational costs.  Similarly, \cite{ghasemzadeh2012} proposes tunable feature selection for wearable embedded systems, where less accurate feature computation can be used at the cost of inference quality. Similarly, \cite{liu1994} represents one of many efforts at using approximate computing to save energy where marginal losses in quality can be afforded. 

More recent efforts have begun to consider hardware variability and methods for mitigating variation in software.  These can roughly be divided into two camps: (1) low-level treatment of variability in hardware and in voltage and frequency scaling (e.g. \cite{teodorescu2008}) and (2) application-level adaptations to meet power requirements.  While low-level treatment of hardware variation is undoubtedly a necessary step forward for commercial processors, application- and process-level adaptations have proven effective methods for combatting variation in low power embedded systems and wireless sensor networks.  Both \cite{matsuda2006} and \cite{garg2007} provide lifetime analyses for wireless sensor networks when considering variability power models, offering insights into what such systems stand to gain from explicit treatment of hardware variation.  Garg et al. estimated that a 37\% system lifetime improvement could be achieved through redundancy efforts that totaled a 20\% increased deployment cost.  To avoid cost increases, application quality or performance can be reduced as in \cite{pant2010}, where video compression codecs are selected based on particular hardware variability `signatures'.

This work is closely related to that of Wanner et al. in \cite{wanner2011}.  There, the authors describe a method for calculating a system-wide optimal duty cycle ratio given known models for active and idle power as well as probability density functions for deployment temperatures. Here we provide an extension to the work in \cite{wanner2011}, showing methods for online learning of power models and providing notions of utility in multi-task applications.  


